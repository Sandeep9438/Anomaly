{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is Dimensionality Reduction? Why is it important in machine ?**\n",
        "\n",
        "> Dimensionality reduction is the process of transforming a dataset with a large number of features or dimensions into a new dataset with a significantly smaller number of features while preserving most of the original data's variance and structure.\n",
        "\n",
        "> **Important in Machine Learning:**\n",
        "\n",
        "> **Combaning the Curse of Dimensionality: **\n",
        ">> In high-dimensional spaces, data points become very sparse (spread out). This makes it hard for machine learning modeles to find meaningful patterns and generalize well. Reducing the dimensions fixes this.\n",
        "\n",
        "> **Increased Efficiency:**\n",
        ">>  Fewer dimensions mean less memory usage and faster training times for the algorithms, leading to better computational performance.\n",
        "\n",
        "> **Preventing Overfitting:**\n",
        ">> By removing redundant or noisy features, the model is forced to learn only the most important signals, which helps improve its generalization capability and prevents it from overfitting to the training data.\n",
        "\n",
        "> **Conclusion:**\n",
        ">> Dimensionality reduction is a critical preprocessing technique that simplifies complex data by reducing the feature count. Its primary goal is to produce faster, more robust, and more accurate machine learning models by mitigating the negative effects of the Curse of Dimensionality and redundant information."
      ],
      "metadata": {
        "id": "ZdxjnnqDNpLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Name and briefly describe three common dimensionality reduction techniques ?**\n",
        "\n",
        "> Dimensionality reduction is the process of transforming a dataset with a large number of features or dimensions into a new dataset with a significantly smaller number of features while preserving most of the original data's variance and structure. 3 common dimensionality reduction techniques are:\n",
        "\n",
        "> **Principal Component Analysis (PCA):**\n",
        ">> It  is the most popular and a linear dimensionality reduction technique. It works by transforming the original, potentially correleted features into a new, smaller set of uncorreleted features called Principal Components (PCs). It helps to reducing the number of variables while retaining as much information (variance) as possible.\n",
        "\n",
        "> **Linear Discriminant Analysis (LDA):**\n",
        ">> It is a supervised learning technique that finds a linear combination of features that separates two or more classes of data. It projects the data in a way that maximizes the distance between class means and minimizes the variance within each class. It is beest for classification problems where the goal is to find a subspace that maximizes class separability.\n",
        "\n",
        "> **Conclushion:**\n",
        ">> In summary, dimensionality reduction is vital for creating robust, efficient, and accurate machine learning models by strategically simplifying the data representation."
      ],
      "metadata": {
        "id": "HIHErg9NRlTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. What is clustering in unsupervised learning? Mention three popular\n",
        "clustering algorithms ?**\n",
        "\n",
        "> Clustering is the process of grouping a set of data points such that data points within the same group (cluster) are more similar to each other than to those in other clusters. 3 Popular Clustering Algorithms are:\n",
        "\n",
        "> **K-Means Clustering:**\n",
        ">>  K-Means is one of the most widely used and simplest clustering algorithms.8 It works by partitioning the data into a pre-specified number of clusters. The algorithm iteratively assigns each data point to the cluster whose mean (or centroid) is the nearest.\n",
        "\n",
        "> **Hierchical Clustering:**\n",
        ">> it is an unsupervised learning method that groups data points into a tree-like hierarchy of clusters, visualized with a dendrogram. It creates nested groups where clusters are either merged together (agglomerative) or split apart (divisive) based on their similarity, without requiring the number of clusters to be specified.\n",
        "\n",
        "> **DBSCAN:**\n",
        ">> It is used for clustering data points based on their density. Unlike algorithms like k-means, DBSCAN does not require the number of clusters to be specified in advance.\n",
        "\n",
        "> **Conclusion:**\n",
        ">> Clustering is a powerful tool for unsupervized lerning, allowing us to uncover hiden structure and natural groupings in unlabeled data. Whether you choose the efficiency of K-Means, the hierarchy of Agglomerative methods, or the shape flexibility of DBSKAN, these algotithms are essential for exploratory data analysis and discovering key insights from complex datasets.\n",
        "\n"
      ],
      "metadata": {
        "id": "340KdqGVUbUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Explain the concept of anomaly detection and its significance ?**\n",
        "\n",
        "> Anomaly Detection, often referred to as Outlier Detection, is a fundamental concept in machine learning. It's used to identify rare items, events, or observations that deviate significantly from the majority of the data and do not conform to a well-defined notion of normal behavior.\n",
        "\n",
        "> **Significance of Anomaly Detection:**\n",
        "\n",
        "> **Financial Fraud Prevention: **\n",
        ">> It is crucial for detecting unusual transaction patterns, money laundering, and credit card fraud that deviates from a customer's typical spending behavior.\n",
        "\n",
        "> **Cybersecurity & Intrusion Detection**:\n",
        ">> Used in Intrusion Detection Systems (IDS) to monitor network traffic and flag unusual activity, such as unauthorized access, login attempts from unfamiliar locations, or sudden spikes in bandwidth usage, which indicate a potential attack.\n",
        "\n",
        "> **Healthcare Monitoring:**\n",
        ">> Used to detect abnormal patient conditions by monitoring vital signs (like heart rate or blood pressure) or analyzing medical images (like X-rays or MRIs) for signs of disease that deviate from the norm.\n",
        "\n",
        "> **Quality Control:**\n",
        ">> In production lines, it spots defects or process malfunctions by analyzing images or sensor data, ensuring high-quality product output.\n",
        "\n",
        "> **Conclusion:**\n",
        ">> Anomaly detection serves as an early warning system for numerous complex real-world systems. Its power lies in its ability to automatically and accurately flag the exceptions that can represent security risks, system failures, or valuable opportunities, thereby ensuring system reliability, integrity, and efficiency.\n"
      ],
      "metadata": {
        "id": "qpmdnJj75WSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. List and briefly describe three types of anomaly detection techniques ?\n",
        "\n",
        "> Anomaly Detection, often referred to as Outlier Detection, is a fundamental concept in machine learning. It's used to identify rare items, events, or observations that deviate significantly from the majority of the data and do not conform to a well-defined notion of normal behavior.\n",
        "\n",
        "> **Statistical Methods:**\n",
        "\n",
        ">>  Assume normal data follows a known distribution (like Gaussian). An anomaly is any data point that falls outside a set number of standard deviations (e.g., the Z-Score method).It foucus on identifying global outliers based on statistical distance from the mean.\n",
        "\n",
        "> **Density-Based Methods:**\n",
        ">> Assume normal points are in dense clusters. Anomalies are points that have a significantly lower local density than their neighbors, suggesting they are isolated."
      ],
      "metadata": {
        "id": "E_jOzJBu9dzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What is time series analysis? Mention two key components of time series data ?**\n",
        "\n",
        "> Time series data is typically decomposed into four main components—Trend, Seasonality, Cyclicity, and Irregularity (Noise)—but the two most significant and commonly modeled components are Trend and Seasonality.\n",
        "\n",
        "> **Trend:**\n",
        ">> It represents the long-term direction or general systematic movement of a time series over an extended period. It is the underlying pattern that shows whether the data is generally increasing (upward trend), decreasing (downward trend), or remaining relatively constant (no trend).\n",
        "\n",
        "> **Seasonality:**\n",
        ">> It refers to a predictable and repeating pattern of variation that occurs at fixed, regular intervals, typically within a calendar year (daily, weekly, monthly, or yearly). These patterns are consistent in their timing and magnitude, often driven by calendar events, holidays, weather conditions, or regular business cycles.\n",
        "\n",
        "> **Conclusion:**\n",
        ">> Trend and Seasonality are the two primary components driving a series' behavior. Identifying and separating the long-term direction (Trend) from the short, regular cycles (Seasonality) is essential for accurately understanding the data's past forces and making reliable forecasts about its future valews."
      ],
      "metadata": {
        "id": "Q74IUSht_61A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Describe the difference between seasonality and cyclic behavior in time\n",
        "series ?**\n",
        "\n",
        "> In time series analysis, data often shows repeated patterns over time. Two important types of repeating patterns are seasonality and cyclic behavior. Although both involve ups and downs in the data, they differ in how regularly they occur and what factors cause them.\n",
        "\n",
        "> **Seasonality:**\n",
        "\n",
        ">> Seasonality refers to fluctuations that repeat at fixed and known intervals. These intervals are usually short, such as daily, weekly, monthly, or yearly. Seasonal patterns are caused by calendar-based or environmental factors, like weather changes, holidays, or weekly shopping habits. Because the timing is predictable, seasonality is easy to detect. For example, sales of ice cream increase every summer, and electricity usage rises every winter.\n",
        "\n",
        "> **Cyclic Behavior:**\n",
        "\n",
        ">> Cyclic behavior refers to patterns that do not repeat at fixed intervals. Cycles are usually longer and irregular, often lasting several years. They are influenced by economic, business, or market forces rather than calendar effects. Because the duration and intensity of cycles vary, they are harder to forecast.\n",
        "\n",
        "> **Conclusion:**\n",
        ">> Both seaonality and cyclic behavior describe repeated movements in a time series, but they differ in timing and cause. Seasonality follows a regular, predictable schedule tied to the calendar, while cycles occur over irregular, longer periods driven by broader economic or natural forces. Understanding this difference helps in choosing the right forcasting methods and improves the accuracy of time series analysis.\n"
      ],
      "metadata": {
        "id": "yE418bXAXjmu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.  Write Python code to perform K-means clustering on a sample dataset ?**"
      ],
      "metadata": {
        "id": "q6iNXlO8D--f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import all required libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Load dataset - 'iris'\n",
        "df = sns.load_dataset(\"iris\")\n",
        "\n",
        "x = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
        "\n",
        "# K-means clustering model\n",
        "kmeans = KMeans(n_clusters = 3, random_state = 1)\n",
        "kmeans.fit(x)\n",
        "\n",
        "print(\"silohoutte score:\", silhouette_score(x, kmeans.labels_))\n",
        "print(\"WCSS distance:\", kmeans.inertia_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5RaLgDfZFa9",
        "outputId": "be6d7a06-ad63-4975-a776-da33a799f6ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "silohoutte score: 0.5511916046195927\n",
            "WCSS distance: 78.85566582597727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. What is inheritance in OOP? Provide a simple example in Python ?**"
      ],
      "metadata": {
        "id": "RNRldPVLZH4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Inheritance is a mechanism in OOP where one class (called the child or derived class) can acquire\n",
        "the properties and behaviors (attributes and methods) of another class (called the parent or base class).\n",
        "It allows you to reuse existing code instead of writing it again, while still being able to extend or modify it.\n",
        "\"\"\"\n",
        "\n",
        "#Here python example\n",
        "class Vehicle:\n",
        "  def __init__(self, model, brand):\n",
        "    self.model = model\n",
        "    self.brand = brand\n",
        "\n",
        "class Car(Vehicle):\n",
        "  def __init__(self, model, brand, price):\n",
        "    super().__init__(model, brand)\n",
        "    self.price = price\n",
        "\n",
        "v = Vehicle('TS1', 'Tesla')\n",
        "print(v.model, v.brand)\n",
        "c = Car('KS1', 'Tata', 1000000)\n",
        "print(c.brand, c.model, c.price)"
      ],
      "metadata": {
        "id": "nTIRsE_cdhrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27e6af4-8d1d-4e2d-cdae-d182eac872ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TS1 Tesla\n",
            "Tata KS1 1000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10: How can time series analysis be used for anomaly detection ?**\n",
        "\n",
        "> Time series anomaly detection focuses on identifying unusual patterns, values, or sudden changes in data over time. These anomalies indicate events that deviate from normal behavior and may signal issues, opportunities, or risks in real-world systems.\n",
        "\n",
        "> Time series analysis helps detect anomalies by first understanding the normal pattern of data — including trends, seasonality, and cycles — and then identifying points or periods where the data behaves unexpectedly. Models learn the expected range of values based on historical behavior. When a new data point significantly deviates from this expected pattern, it is flagged as an anomaly.\n",
        "\n",
        "> **Conclusion:**\n",
        ">> By modeling normal time-based behavior, time series analysis makes it easier to spot unusual events that stand out from expected patterns. This is valuble in many areas such as fraud detection, equipment failure prediction etc."
      ],
      "metadata": {
        "id": "Oj8ih3h-ZPh0"
      }
    }
  ]
}